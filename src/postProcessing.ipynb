{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing: validate model with reddit data\n",
    "- 1) add vader sentiment to preprocessed reddit posts and comments \n",
    "- 2) predict spoiler with trained-model (input: wordvec + sentiment score)\n",
    "- 3) validation report\n",
    "- 4) output db tables: posts, comments; each contains origin post, karma, sentiment, and pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import arrow\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import _pickle as Pickle\n",
    "loadPickle = lambda f: Pickle.load(open(f, 'rb'))\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Reddit data and word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment vec shape:  21105\n",
      "comment df shape:   21105\n",
      "post vec shape:     16490\n",
      "post df shape:      16490\n"
     ]
    }
   ],
   "source": [
    "com1 = pd.read_csv('comments2018final_all.csv', low_memory=False)\n",
    "com2 = pd.read_csv('comments2019final_all.csv', low_memory=False)\n",
    "com2018 = loadPickle('comment2018vec.p')\n",
    "com2019 = loadPickle('comment2019vec.p')\n",
    "\n",
    "com = pd.concat([com1, com2], sort=True)\n",
    "com_vec = np.hstack([com2018, com2019])\n",
    "\n",
    "######################################################################\n",
    "post1 = pd.read_csv('posts2018final_all.csv', low_memory=False)\n",
    "post2018 = loadPickle('movie2018title_vec.p')\n",
    "post2 = pd.read_csv('posts2019final_all.csv', low_memory=False)\n",
    "post2019 = loadPickle('movie2019title_vec.p')\n",
    "\n",
    "# Join data\n",
    "pos = pd.concat([post1, post2], sort=True)\n",
    "pos_vec = np.hstack([post2018, post2019])\n",
    "com = com.reset_index(drop=True)\n",
    "pos = pos.reset_index(drop=True)\n",
    "\n",
    "# Clean NA\n",
    "com_id = com[com.body_clean.apply(type)!=np.float].index\n",
    "pos_id = pos[pos.title_clean.apply(type)!=np.float].index\n",
    "pos.id = pos.id.astype(str)\n",
    "pos_id = np.setdiff1d(pos_id, pos[pos['id']=='inf'].index)\n",
    "\n",
    "com = com[com.index.isin(com_id)]\n",
    "pos = pos[pos.index.isin(pos_id)]\n",
    "com_vec = com_vec[com_id]\n",
    "pos_vec = pos_vec[pos_id]\n",
    "\n",
    "# ######################################################################\n",
    "print(f'comment vec shape: {com_vec.shape[0]:>6}\\ncomment df shape: {com.shape[0]:>7}\\n'+\n",
    "     f'post vec shape: {pos_vec.shape[0]:>9}\\npost df shape: {pos.shape[0]:>10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "def sent(sentence):\n",
    "    return analyser.polarity_scores(sentence)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRED SENTIMENT\n",
    "pool = Pool(32)\n",
    "com['vader'] = com.body_clean.apply(sent)\n",
    "pos['vader'] = pos.title_clean.apply(sent)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SPOILER PRED MODEL \n",
    "\n",
    "model = loadPickle('lgb.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE DATA FOR MODEL PREDICT\n",
    "com_vec = np.array([x for x in com_vec]).reshape(-1, 300)\n",
    "pos_vec = np.array([x for x in pos_vec]).reshape(-1, 300)\n",
    "com_vec = np.hstack([com_vec, com.vader.values.reshape(-1, 1)])\n",
    "pos_vec = np.hstack([pos_vec, pos.vader.values.reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "com['pred'] = model.predict(com_vec).astype(int)\n",
    "pos['pred'] = model.predict(pos_vec).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com.pred.unique()\n",
    "pos.pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "com['time'] = com.created_utc.apply(lambda t: arrow.get(t))\n",
    "pos['time'] = pos.created_utc.apply(lambda t: arrow.get(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "com.score = com.score.astype(int)\n",
    "# pos.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "com[['id', 'link_id', 'author', 'score', 'pred', 'vader', 'body', 'time']].to_csv('DB_comments.csv', index=False)\n",
    "pos[['id', 'author', 'score', 'pred', 'vader', 'num_comments', 'title', 'time']].to_csv('DB_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos[pos.index==6829]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spoiler examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Batman returns and the destruction of childhood [SPOILERS]',\n",
       " \"Seeing as there isn't an official /r Movies discussion, *I, Tonya* (Unofficial Spoilers Discussion)\",\n",
       " 'What was the best ending scene of 2017? (SPOILERS)',\n",
       " '[Spoilers] Something really interesting in “Lady Bird” that I don’t see anyone talking about',\n",
       " 'SPLIT parallel scene(SPOILERS)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('spoiler examples:') # stopword not incldue spolier\n",
    "[x for x in pos[pos.title_clean.str.contains('spoiler')].title][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reddit validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spos = pos[(pos.title.apply(lambda s: s.lower()).str.contains('spoiler')) & \\\n",
    "    (~pos.title.apply(lambda s: s.lower()).str.contains('no spoiler'))]\\\n",
    "     [['title', 'vader', 'pred']]\n",
    "scom = com[(com.body.apply(lambda s: s.lower()).str.contains('spoiler')) & \\\n",
    "    (~com.body.apply(lambda s: s.lower()).str.contains('no spoiler'))]\\\n",
    "     [['body', 'vader', 'pred']]\n",
    "\n",
    "scom = scom.rename({'body':'title'}, axis=1)\n",
    "spos['is_spoiler'] = 1\n",
    "scom['is_spoiler'] = 1\n",
    "s = spos.append(scom, sort=True)\n",
    "s.head(2)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos[pos.title.apply(lambda x: x.lower()).str.contains('no spoiler')]\n",
    "# com[com.body.apply(lambda x: x.lower()).str.contains('no spoiler')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ns = pos[~pos.title_clean.str.contains('spoiler')][['title', 'vader', 'pred']].\\\n",
    "#     sample(n=len(s), random_state=12)\n",
    "ns = pos[pos.title.apply(lambda x: x.lower()).str.contains('no spoiler')][['title', 'vader', 'pred']]\n",
    "ns['is_spoiler'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vader</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>In the last Jedi (no spoilers), there is a shi...</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>Most critics said that his career was over whe...</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>Hm. Haven't seen Incendies, but I saw Heridita...</td>\n",
       "      <td>0.4287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title   vader  pred  \\\n",
       "1504   In the last Jedi (no spoilers), there is a shi... -0.1531     1   \n",
       "3682   Most critics said that his career was over whe...  0.2960     0   \n",
       "14693  Hm. Haven't seen Incendies, but I saw Heridita...  0.4287     0   \n",
       "\n",
       "       is_spoiler  \n",
       "1504            0  \n",
       "3682            0  \n",
       "14693           0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cs = com[~com.body_clean.str.contains('spoiler')][['body', 'vader', 'pred']].\\\n",
    "#     sample(n=len(s), random_state=12)\n",
    "cs =  com[com.body.apply(lambda x: x.lower()).str.contains('no spoiler')][['body', 'vader', 'pred']]\n",
    "cs['is_spoiler'] = 0\n",
    "cs = cs.rename({'body':'title'}, axis=1)\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>pred</th>\n",
       "      <th>title</th>\n",
       "      <th>vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Batman returns and the destruction of childhoo...</td>\n",
       "      <td>-0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Seeing as there isn't an official /r Movies di...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>What was the best ending scene of 2017? (SPOIL...</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Spoilers] Something really interesting in “La...</td>\n",
       "      <td>0.4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SPLIT parallel scene(SPOILERS)</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Did Joi really love K in Blade Runner 2049? Wh...</td>\n",
       "      <td>0.6697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Can we all shut up about bombs in space now?! ...</td>\n",
       "      <td>-0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Potential Spoilers] In regards to Star Wars V...</td>\n",
       "      <td>-0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I have a question about the ending of Dunkirk ...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bryan Young explains Canto Bight's importance ...</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_spoiler  pred                                              title  \\\n",
       "15            1     1  Batman returns and the destruction of childhoo...   \n",
       "35            1     0  Seeing as there isn't an official /r Movies di...   \n",
       "42            1     0  What was the best ending scene of 2017? (SPOIL...   \n",
       "50            1     0  [Spoilers] Something really interesting in “La...   \n",
       "101           1     0                     SPLIT parallel scene(SPOILERS)   \n",
       "168           1     0  Did Joi really love K in Blade Runner 2049? Wh...   \n",
       "187           1     1  Can we all shut up about bombs in space now?! ...   \n",
       "209           1     1  [Potential Spoilers] In regards to Star Wars V...   \n",
       "261           1     1  I have a question about the ending of Dunkirk ...   \n",
       "314           1     1  Bryan Young explains Canto Bight's importance ...   \n",
       "\n",
       "      vader  \n",
       "15  -0.5719  \n",
       "35   0.0000  \n",
       "42   0.6369  \n",
       "50   0.4576  \n",
       "101  0.0000  \n",
       "168  0.6697  \n",
       "187 -0.4939  \n",
       "209 -0.6249  \n",
       "261  0.0000  \n",
       "314  0.3612  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reddit_test = s.append(ns, sort=True).append(cs, sort=True)\n",
    "display(reddit_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batman returns and the destruction of childhood [SPOILERS]',\n",
       " \"Seeing as there isn't an official /r Movies discussion, *I, Tonya* (Unofficial Spoilers Discussion)\",\n",
       " 'What was the best ending scene of 2017? (SPOILERS)',\n",
       " '[Spoilers] Something really interesting in “Lady Bird” that I don’t see anyone talking about',\n",
       " 'SPLIT parallel scene(SPOILERS)',\n",
       " 'Did Joi really love K in Blade Runner 2049? What’s your take on it? spoilers*',\n",
       " 'Can we all shut up about bombs in space now?! (Last Jedi Spoilers) from the official visual guide by Pablo Hidalgo',\n",
       " '[Potential Spoilers] In regards to Star Wars VIII happening so closely to VII, would adding a fourth movie to the storyline create enough wiggle room to further develop the conflict and answer questions that were previously left open-ended?',\n",
       " 'I have a question about the ending of Dunkirk [Spoilers]',\n",
       " \"Bryan Young explains Canto Bight's importance to the story of The Last Jedi [all spoilers]\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in reddit_test.head(10).title]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.75      0.14        28\n",
      "           1       0.95      0.37      0.53       390\n",
      "\n",
      "    accuracy                           0.39       418\n",
      "   macro avg       0.52      0.56      0.34       418\n",
      "weighted avg       0.90      0.39      0.51       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(reddit_test.is_spoiler, reddit_test.pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stop words should have included \"no\" so n-grams will catch it?\n",
    "- observation: not all spolier marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
